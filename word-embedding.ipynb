{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Word Embedding and Feature Representation**\n---\n## **Introduction to Word Embedding**\n- **Word Embedding** is a technique used in Natural Language Processing (NLP) to convert words into vectors. \n- This technique is vital for feeding textual data into neural networks. Like other layers such as Dense layers, neural networks have an **Embedding Layer** dedicated to converting words into vectors.\n- The embedding layer uses word embedding techniques to transform input words into vector representations, which are essential for processing textual data within neural networks.\n\n## **Feature Representation**\n- **Feature Representation** refers to the vectorized form of words created by embedding techniques.\n- Each word in a dataset is converted into a vector of a certain dimension, representing various features or attributes of the word.\n  \n## **One-Hot Encoding**\n- **One-Hot Encoding** is an early and simple method to represent words as vectors.\n- In this technique, each word in the vocabulary is represented by a binary vector with a dimension equal to the vocabulary size. \n- For example, if the vocabulary size is 10,000, each word is represented as a vector of length 10,000 with a single `1` at the index corresponding to the word, and all other positions are `0`.\n  \n  **Example:**\n  - For the word \"man,\" if it appears at index 5000 in the vocabulary, the vector will be `[0, 0, 0, ..., 1, 0, 0, ...]`.\n  - For the word \"boy,\" if it appears at index 2000, the vector will be `[0, 0, 1, ..., 0, 0, 0, ...]`.\n\n- **Sparse Matrix Problem**: One-Hot Encoding results in sparse matrices, as most values are zeros. This sparsity can lead to overfitting because the vectors lack meaningful relationships between words.\n\n### **Limitations of One-Hot Encoding**\n- **Inefficiency**: The resulting vectors are high-dimensional (equal to the vocabulary size), leading to large, sparse matrices.\n- **No Semantic Information**: One-hot vectors do not capture any semantic relationships between words. For instance, the words \"man\" and \"boy\" might be semantically similar, but their one-hot representations do not reflect this.\n\n## **Word Embedding: A Solution**\n- **Word Embedding** addresses the limitations of one-hot encoding by creating dense vectors that capture semantic relationships between words.\n- Unlike one-hot encoding, where the vector length equals the vocabulary size, word embeddings use a fixed, lower-dimensional space to represent words.\n\n  **Example:**\n  - The words \"man\" and \"boy\" might have vectors that are close to each other in the embedding space, reflecting their semantic similarity.\n\n## **Word2Vec**\n- **Word2Vec** is a popular word embedding technique developed by Google.\n- **Word2Vec** works by training a neural network on a large corpus of text to predict words based on their context. This results in vectors where semantically similar words have similar representations.\n- **Types of Word2Vec**:\n  - **Skip-gram**: Trains a model to predict surrounding words given a central word.\n  - **Continuous Bag of Words (CBOW)**: Predicts a central word based on its surrounding context.\n\n## **Feature Representation in Word Embedding**\n- In word embedding, each word is represented by a dense vector of fixed dimensions (e.g., 300 dimensions).\n- **Feature Representation**: These vectors are determined by capturing relationships between words along different features like **Gender**, **Royalty**, **Age**, and **Food**.\n\n  **Example:**\n  - For the word \"boy\":\n    - **Gender**: -1 (representing masculine)\n    - **Royalty**: 0.01 (low association with royalty)\n  - For the word \"King\":\n    - **Gender**: 0.92 (high association with male gender)\n    - **Royalty**: 0.95 (high association with royalty)\n\n- The resulting vector captures the word's relationships across these features, creating a more meaningful representation.\n\n## **Training Word Embeddings**\n- The word embedding vectors are learned through training on large text corpora.\n- Techniques like **Word2Vec** and **GloVe** (Global Vectors for Word Representation) are commonly used for training embeddings.\n- **GloVe** is another word embedding technique similar to Word2Vec, focusing on capturing global statistical information from the corpus.\n\n## **Parameters to Consider**\n1. **Vocabulary Size**: The total number of unique words in the dataset.\n   - Example: 10,000 words.\n2. **Feature Dimension**: The dimensionality of the embedding space.\n   - Commonly used dimensions: 100, 200, 300.\n   - Word2Vec and GloVe often use 300 dimensions for effective representation.\n\n## **Practical Implementation**\n- Embedding layers using these word embedding techniques are integrated into neural networks.\n- The next step involves applying these embeddings in practical tasks, such as training a **Simple RNN** or other deep learning models, to improve performance and handle textual data effectively.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-08-22T08:22:40.467286Z","iopub.execute_input":"2024-08-22T08:22:40.467701Z","iopub.status.idle":"2024-08-22T08:23:01.205155Z","shell.execute_reply.started":"2024-08-22T08:22:40.467667Z","shell.execute_reply":"2024-08-22T08:23:01.203808Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install keras","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:23:01.207885Z","iopub.execute_input":"2024-08-22T08:23:01.208396Z","iopub.status.idle":"2024-08-22T08:23:16.344366Z","shell.execute_reply.started":"2024-08-22T08:23:01.208287Z","shell.execute_reply":"2024-08-22T08:23:16.343024Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (2.15.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import one_hot","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:23:16.346123Z","iopub.execute_input":"2024-08-22T08:23:16.346482Z","iopub.status.idle":"2024-08-22T08:23:31.621457Z","shell.execute_reply.started":"2024-08-22T08:23:16.346450Z","shell.execute_reply":"2024-08-22T08:23:31.620139Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-08-22 08:23:18.756968: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-22 08:23:18.757114: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-22 08:23:18.928797: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"### sentences\nsent=[  'the glass of milk',\n     'the glass of juice',\n     'the cup of tea',\n    'I am a good boy',\n     'I am a good developer',\n     'understand the meaning of words',\n     'your videos are good',]\n\nsent","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:23:31.624918Z","iopub.execute_input":"2024-08-22T08:23:31.625835Z","iopub.status.idle":"2024-08-22T08:23:31.637488Z","shell.execute_reply.started":"2024-08-22T08:23:31.625787Z","shell.execute_reply":"2024-08-22T08:23:31.636162Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['the glass of milk',\n 'the glass of juice',\n 'the cup of tea',\n 'I am a good boy',\n 'I am a good developer',\n 'understand the meaning of words',\n 'your videos are good']"},"metadata":{}}]},{"cell_type":"code","source":"sent[0:3]","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:23:31.638899Z","iopub.execute_input":"2024-08-22T08:23:31.639454Z","iopub.status.idle":"2024-08-22T08:23:31.653367Z","shell.execute_reply.started":"2024-08-22T08:23:31.639417Z","shell.execute_reply":"2024-08-22T08:23:31.651817Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['the glass of milk', 'the glass of juice', 'the cup of tea']"},"metadata":{}}]},{"cell_type":"code","source":"## Define the vocabulary size\nvoc_size=10000","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:23:31.655161Z","iopub.execute_input":"2024-08-22T08:23:31.655513Z","iopub.status.idle":"2024-08-22T08:23:31.666855Z","shell.execute_reply.started":"2024-08-22T08:23:31.655485Z","shell.execute_reply":"2024-08-22T08:23:31.665525Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for words in sent:\n    print(words)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:23:31.668905Z","iopub.execute_input":"2024-08-22T08:23:31.669370Z","iopub.status.idle":"2024-08-22T08:23:31.681347Z","shell.execute_reply.started":"2024-08-22T08:23:31.669332Z","shell.execute_reply":"2024-08-22T08:23:31.680041Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"the glass of milk\nthe glass of juice\nthe cup of tea\nI am a good boy\nI am a good developer\nunderstand the meaning of words\nyour videos are good\n","output_type":"stream"}]},{"cell_type":"code","source":"# OHE Representation\none_hot_repr = [one_hot(words, voc_size) for words in sent]\none_hot_repr","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:23:31.683007Z","iopub.execute_input":"2024-08-22T08:23:31.683536Z","iopub.status.idle":"2024-08-22T08:23:31.699070Z","shell.execute_reply.started":"2024-08-22T08:23:31.683500Z","shell.execute_reply":"2024-08-22T08:23:31.697700Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[[8441, 4969, 9646, 3453],\n [8441, 4969, 9646, 774],\n [8441, 5972, 9646, 7629],\n [9360, 8974, 175, 6288, 3316],\n [9360, 8974, 175, 6288, 8527],\n [2944, 8441, 9895, 9646, 2079],\n [7838, 7387, 7107, 6288]]"},"metadata":{}}]},{"cell_type":"code","source":"# Word Embedding Representation\nfrom tensorflow.keras.models import Sequential\n# Sequential: This module provides a linear stack of layers, allowing you to easily create and manage a neural network model in a step-by-step manner.\n\nfrom tensorflow.keras.layers import Embedding\n# Embedding: This layer is used to convert categorical data (like words) into dense vectors of fixed size, which are more suitable for input to a neural network.\n\n#from tensorflow.keras.processing.sequence import pad_sequences\nfrom tensorflow.keras.utils import pad_sequences\n# pad_sequences: This utility function pads sequences of varying lengths to ensure that they all have the same length, making them suitable for processing by neural networks.\n\nimport numpy as np\n# numpy: A fundamental library for numerical computing in Python, used here for efficient array and matrix operations.","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:23:31.700864Z","iopub.execute_input":"2024-08-22T08:23:31.701361Z","iopub.status.idle":"2024-08-22T08:23:31.713035Z","shell.execute_reply.started":"2024-08-22T08:23:31.701296Z","shell.execute_reply":"2024-08-22T08:23:31.711840Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"The `pad_sequences` function from tensorflow.keras.utils is commonly used to ensure that all sequences in a dataset have the same length. It pads shorter sequences with zeros (or another specified value) and truncates longer sequences to a specified maximum length. This is particularly useful when working with text data, such as for input to Recurrent Neural Networks (RNNs), where all input sequences need to be of the same length.","metadata":{}},{"cell_type":"code","source":"sent_len = 8\nembedded_docs = pad_sequences(one_hot_repr, padding='pre', maxlen = sent_len)\nprint(embedded_docs)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:29:30.330385Z","iopub.execute_input":"2024-08-22T08:29:30.330838Z","iopub.status.idle":"2024-08-22T08:29:30.338202Z","shell.execute_reply.started":"2024-08-22T08:29:30.330803Z","shell.execute_reply":"2024-08-22T08:29:30.336900Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[[   0    0    0    0 8441 4969 9646 3453]\n [   0    0    0    0 8441 4969 9646  774]\n [   0    0    0    0 8441 5972 9646 7629]\n [   0    0    0 9360 8974  175 6288 3316]\n [   0    0    0 9360 8974  175 6288 8527]\n [   0    0    0 2944 8441 9895 9646 2079]\n [   0    0    0    0 7838 7387 7107 6288]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Feature Representation\n\ndim = 10","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:30:42.984125Z","iopub.execute_input":"2024-08-22T08:30:42.985214Z","iopub.status.idle":"2024-08-22T08:30:42.989995Z","shell.execute_reply.started":"2024-08-22T08:30:42.985175Z","shell.execute_reply":"2024-08-22T08:30:42.988775Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(voc_size, dim, input_length=sent_len))\nmodel.compile(\"adam\", \"mse\")","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:33:31.652134Z","iopub.execute_input":"2024-08-22T08:33:31.652600Z","iopub.status.idle":"2024-08-22T08:33:31.726654Z","shell.execute_reply.started":"2024-08-22T08:33:31.652564Z","shell.execute_reply":"2024-08-22T08:33:31.725446Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"[Embedding Layer docs](https://keras.io/api/layers/core_layers/embedding/)","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:33:45.913682Z","iopub.execute_input":"2024-08-22T08:33:45.914112Z","iopub.status.idle":"2024-08-22T08:33:45.935997Z","shell.execute_reply.started":"2024-08-22T08:33:45.914081Z","shell.execute_reply":"2024-08-22T08:33:45.934803Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 8, 10)             100000    \n                                                                 \n=================================================================\nTotal params: 100000 (390.62 KB)\nTrainable params: 100000 (390.62 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.predict(embedded_docs)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:34:45.195357Z","iopub.execute_input":"2024-08-22T08:34:45.195824Z","iopub.status.idle":"2024-08-22T08:34:45.451850Z","shell.execute_reply.started":"2024-08-22T08:34:45.195789Z","shell.execute_reply":"2024-08-22T08:34:45.450248Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 150ms/step\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array([[[-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.03157163, -0.00711571, -0.0286233 ,  0.03488598,\n         -0.03657383, -0.01090366,  0.03258919, -0.00120535,\n          0.00400615,  0.02875033],\n        [-0.02574574, -0.00962896,  0.03425619, -0.00581864,\n         -0.02202575,  0.03405695,  0.00866314,  0.02586682,\n          0.00402568,  0.03387472],\n        [ 0.02461665, -0.00123334, -0.00572918,  0.04080024,\n         -0.04559186,  0.02747586, -0.00947763, -0.04452793,\n          0.04065043,  0.04555818],\n        [-0.04945592,  0.00362747,  0.02535501, -0.03093313,\n          0.00578644, -0.04121142,  0.00744656,  0.00779502,\n          0.02401557, -0.02070869]],\n\n       [[-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.03157163, -0.00711571, -0.0286233 ,  0.03488598,\n         -0.03657383, -0.01090366,  0.03258919, -0.00120535,\n          0.00400615,  0.02875033],\n        [-0.02574574, -0.00962896,  0.03425619, -0.00581864,\n         -0.02202575,  0.03405695,  0.00866314,  0.02586682,\n          0.00402568,  0.03387472],\n        [ 0.02461665, -0.00123334, -0.00572918,  0.04080024,\n         -0.04559186,  0.02747586, -0.00947763, -0.04452793,\n          0.04065043,  0.04555818],\n        [-0.01908268,  0.01484713,  0.00509615,  0.03974459,\n         -0.03040993,  0.01811179, -0.02791041, -0.00513961,\n          0.01542639, -0.0083055 ]],\n\n       [[-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.03157163, -0.00711571, -0.0286233 ,  0.03488598,\n         -0.03657383, -0.01090366,  0.03258919, -0.00120535,\n          0.00400615,  0.02875033],\n        [-0.0287133 ,  0.04177227, -0.04440799,  0.04927436,\n         -0.01142026,  0.04159746, -0.00297469, -0.02954836,\n         -0.0188064 ,  0.00303944],\n        [ 0.02461665, -0.00123334, -0.00572918,  0.04080024,\n         -0.04559186,  0.02747586, -0.00947763, -0.04452793,\n          0.04065043,  0.04555818],\n        [-0.0493644 ,  0.03785212,  0.03550861,  0.00185202,\n          0.00961802, -0.04696463,  0.04336233, -0.04723361,\n          0.00947888,  0.03128469]],\n\n       [[-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [ 0.00052307,  0.00849062,  0.01607673,  0.02681568,\n         -0.00179094, -0.02953245,  0.01702081, -0.04152522,\n          0.04048289, -0.04861113],\n        [ 0.04118953,  0.00140054, -0.02378814, -0.0388782 ,\n         -0.03707634,  0.00382162, -0.00363987,  0.02936037,\n         -0.04507723,  0.03878596],\n        [-0.04888229,  0.02015385, -0.01798811,  0.02592937,\n         -0.01692779, -0.04340178, -0.03756106,  0.02331853,\n         -0.00962184, -0.04303   ],\n        [ 0.00282975, -0.04428691, -0.02391206,  0.0039    ,\n         -0.00116454,  0.03089345, -0.00430633, -0.02653319,\n         -0.00970211,  0.04494283],\n        [ 0.01749958,  0.0126969 , -0.03830936,  0.01726869,\n          0.02654919, -0.03349413,  0.04953882, -0.0470382 ,\n          0.00766547,  0.04492286]],\n\n       [[-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [ 0.00052307,  0.00849062,  0.01607673,  0.02681568,\n         -0.00179094, -0.02953245,  0.01702081, -0.04152522,\n          0.04048289, -0.04861113],\n        [ 0.04118953,  0.00140054, -0.02378814, -0.0388782 ,\n         -0.03707634,  0.00382162, -0.00363987,  0.02936037,\n         -0.04507723,  0.03878596],\n        [-0.04888229,  0.02015385, -0.01798811,  0.02592937,\n         -0.01692779, -0.04340178, -0.03756106,  0.02331853,\n         -0.00962184, -0.04303   ],\n        [ 0.00282975, -0.04428691, -0.02391206,  0.0039    ,\n         -0.00116454,  0.03089345, -0.00430633, -0.02653319,\n         -0.00970211,  0.04494283],\n        [-0.01258238,  0.02362294,  0.01830519,  0.02159449,\n          0.02181312,  0.00311827,  0.04982581, -0.01237495,\n          0.04544519, -0.03030075]],\n\n       [[-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.03856262,  0.02538177,  0.02489344, -0.04424736,\n         -0.00782604, -0.02936206, -0.0264449 ,  0.01254475,\n          0.03648039,  0.02008427],\n        [-0.03157163, -0.00711571, -0.0286233 ,  0.03488598,\n         -0.03657383, -0.01090366,  0.03258919, -0.00120535,\n          0.00400615,  0.02875033],\n        [ 0.04661587, -0.00122881,  0.02122745, -0.02994864,\n         -0.01964881,  0.01481699, -0.04687345,  0.01452564,\n         -0.01344151,  0.02676517],\n        [ 0.02461665, -0.00123334, -0.00572918,  0.04080024,\n         -0.04559186,  0.02747586, -0.00947763, -0.04452793,\n          0.04065043,  0.04555818],\n        [ 0.02183049, -0.0467095 ,  0.01060935, -0.04886352,\n         -0.0289953 ,  0.01946788, -0.02666952,  0.04117544,\n          0.03086298,  0.01199497]],\n\n       [[-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [-0.01924653, -0.03774593,  0.00947177,  0.01011114,\n         -0.03010894, -0.02946844,  0.03806892,  0.00112319,\n          0.02736178,  0.00875439],\n        [ 0.02482479, -0.04749073, -0.006871  ,  0.03903569,\n          0.01554111, -0.03461652, -0.01583353,  0.01368464,\n          0.0341393 , -0.03540014],\n        [ 0.02456306,  0.03839618,  0.01745098,  0.02624649,\n         -0.00322646, -0.02708345,  0.0468885 ,  0.00331825,\n          0.0493456 ,  0.00290357],\n        [ 0.04810269,  0.00259465,  0.04589436,  0.00915296,\n          0.02826614, -0.01904209,  0.03674687,  0.03067733,\n          0.03011193,  0.04954977],\n        [ 0.00282975, -0.04428691, -0.02391206,  0.0039    ,\n         -0.00116454,  0.03089345, -0.00430633, -0.02653319,\n         -0.00970211,  0.04494283]]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"embedded_docs[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:35:40.756712Z","iopub.execute_input":"2024-08-22T08:35:40.757160Z","iopub.status.idle":"2024-08-22T08:35:40.765282Z","shell.execute_reply.started":"2024-08-22T08:35:40.757128Z","shell.execute_reply":"2024-08-22T08:35:40.763764Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array([   0,    0,    0,    0, 8441, 4969, 9646, 3453], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"model.predict(embedded_docs[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-22T08:37:05.286402Z","iopub.execute_input":"2024-08-22T08:37:05.286891Z","iopub.status.idle":"2024-08-22T08:37:05.432311Z","shell.execute_reply.started":"2024-08-22T08:37:05.286858Z","shell.execute_reply":"2024-08-22T08:37:05.431069Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 65ms/step\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array([[-0.01924653, -0.03774593,  0.00947177,  0.01011114, -0.03010894,\n        -0.02946844,  0.03806892,  0.00112319,  0.02736178,  0.00875439],\n       [-0.01924653, -0.03774593,  0.00947177,  0.01011114, -0.03010894,\n        -0.02946844,  0.03806892,  0.00112319,  0.02736178,  0.00875439],\n       [-0.01924653, -0.03774593,  0.00947177,  0.01011114, -0.03010894,\n        -0.02946844,  0.03806892,  0.00112319,  0.02736178,  0.00875439],\n       [-0.01924653, -0.03774593,  0.00947177,  0.01011114, -0.03010894,\n        -0.02946844,  0.03806892,  0.00112319,  0.02736178,  0.00875439],\n       [-0.03157163, -0.00711571, -0.0286233 ,  0.03488598, -0.03657383,\n        -0.01090366,  0.03258919, -0.00120535,  0.00400615,  0.02875033],\n       [-0.02574574, -0.00962896,  0.03425619, -0.00581864, -0.02202575,\n         0.03405695,  0.00866314,  0.02586682,  0.00402568,  0.03387472],\n       [ 0.02461665, -0.00123334, -0.00572918,  0.04080024, -0.04559186,\n         0.02747586, -0.00947763, -0.04452793,  0.04065043,  0.04555818],\n       [-0.04945592,  0.00362747,  0.02535501, -0.03093313,  0.00578644,\n        -0.04121142,  0.00744656,  0.00779502,  0.02401557, -0.02070869]],\n      dtype=float32)"},"metadata":{}}]}]}