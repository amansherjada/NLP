{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7bd4177",
   "metadata": {
    "papermill": {
     "duration": 0.019624,
     "end_time": "2024-07-18T13:23:17.341854",
     "exception": false,
     "start_time": "2024-07-18T13:23:17.322230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "**Text preprocessing in NLP** is the process of cleaning and preparing raw text data for analysis. It includes steps like removing noise (e.g., HTML tags, special characters), normalizing case, correcting spelling errors, tokenizing text into words or sentences, removing stop words, stripping punctuation, and performing lemmatization or stemming to reduce words to their base forms. Advanced preprocessing may involve POS tagging, named entity recognition, and feature extraction techniques such as TF-IDF or word embeddings. This process enhances the quality and performance of NLP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321f2a24",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:17.382552Z",
     "iopub.status.busy": "2024-07-18T13:23:17.382147Z",
     "iopub.status.idle": "2024-07-18T13:23:18.357100Z",
     "shell.execute_reply": "2024-07-18T13:23:18.355727Z"
    },
    "papermill": {
     "duration": 0.998477,
     "end_time": "2024-07-18T13:23:18.359848",
     "exception": false,
     "start_time": "2024-07-18T13:23:17.361371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696cdf89",
   "metadata": {
    "papermill": {
     "duration": 0.020206,
     "end_time": "2024-07-18T13:23:18.399631",
     "exception": false,
     "start_time": "2024-07-18T13:23:18.379425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Lowercasing\n",
    "\n",
    "**Lowercasing** refers to the process of converting all characters in a text to lowercase. This standardization helps in reducing the complexity of text data by treating words with different cases (e.g., \"Apple\" and \"apple\") as the same word, thereby improving the efficiency and accuracy of subsequent text processing and analysis steps. Lowercasing is particularly useful in ensuring uniformity and consistency in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82ff00e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:18.441580Z",
     "iopub.status.busy": "2024-07-18T13:23:18.441015Z",
     "iopub.status.idle": "2024-07-18T13:23:19.959105Z",
     "shell.execute_reply": "2024-07-18T13:23:19.958135Z"
    },
    "papermill": {
     "duration": 1.542716,
     "end_time": "2024-07-18T13:23:19.961864",
     "exception": false,
     "start_time": "2024-07-18T13:23:18.419148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabe54a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:20.003614Z",
     "iopub.status.busy": "2024-07-18T13:23:20.003190Z",
     "iopub.status.idle": "2024-07-18T13:23:20.025494Z",
     "shell.execute_reply": "2024-07-18T13:23:20.024325Z"
    },
    "papermill": {
     "duration": 0.045794,
     "end_time": "2024-07-18T13:23:20.028074",
     "exception": false,
     "start_time": "2024-07-18T13:23:19.982280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4290942a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:20.069685Z",
     "iopub.status.busy": "2024-07-18T13:23:20.069261Z",
     "iopub.status.idle": "2024-07-18T13:23:20.076864Z",
     "shell.execute_reply": "2024-07-18T13:23:20.075805Z"
    },
    "papermill": {
     "duration": 0.031244,
     "end_time": "2024-07-18T13:23:20.079265",
     "exception": false,
     "start_time": "2024-07-18T13:23:20.048021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. it just never gets old, despite my having seen it some 15 or more times in the last 25 years. paul lukas\\' performance brings tears to my eyes, and bette davis, in one of her very few truly sympathetic roles, is a delight. the kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. and the mother\\'s slow awakening to what\\'s happening in the world and under her own roof is believable and startling. if i had a dozen thumbs, they\\'d all be \"up\" for this movie.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"][5].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "962d689b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:20.122100Z",
     "iopub.status.busy": "2024-07-18T13:23:20.121131Z",
     "iopub.status.idle": "2024-07-18T13:23:20.337243Z",
     "shell.execute_reply": "2024-07-18T13:23:20.336233Z"
    },
    "papermill": {
     "duration": 0.240483,
     "end_time": "2024-07-18T13:23:20.339835",
     "exception": false,
     "start_time": "2024-07-18T13:23:20.099352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"review\"] = df[\"review\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f25a15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:20.381373Z",
     "iopub.status.busy": "2024-07-18T13:23:20.380928Z",
     "iopub.status.idle": "2024-07-18T13:23:20.390055Z",
     "shell.execute_reply": "2024-07-18T13:23:20.388952Z"
    },
    "papermill": {
     "duration": 0.033141,
     "end_time": "2024-07-18T13:23:20.392940",
     "exception": false,
     "start_time": "2024-07-18T13:23:20.359799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. <br /><br />the...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ecc0fd",
   "metadata": {
    "papermill": {
     "duration": 0.020005,
     "end_time": "2024-07-18T13:23:20.434661",
     "exception": false,
     "start_time": "2024-07-18T13:23:20.414656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Remove HTML tags using Regular expressions\n",
    "\n",
    "We remove HTML tags from text for several key reasons:\n",
    "\n",
    "1. **Clean Text**: HTML tags don't contribute to the actual content, only to its structure and presentation.\n",
    "2. **Normalization**: Removing tags helps standardize the text, making it easier to process uniformly.\n",
    "3. **Preprocessing**: Tags can interfere with tokenization and other text processing steps.\n",
    "4. **Accuracy**: Clean text improves the performance of NLP models by focusing on meaningful content.\n",
    "5. **Consistency**: Ensures uniformity across different text sources, simplifying downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "393950ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:20.477798Z",
     "iopub.status.busy": "2024-07-18T13:23:20.477372Z",
     "iopub.status.idle": "2024-07-18T13:23:20.483286Z",
     "shell.execute_reply": "2024-07-18T13:23:20.482008Z"
    },
    "papermill": {
     "duration": 0.030561,
     "end_time": "2024-07-18T13:23:20.486004",
     "exception": false,
     "start_time": "2024-07-18T13:23:20.455443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile(\"<.*?>\")\n",
    "    return pattern.sub(r\"\", text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e433a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:20.528448Z",
     "iopub.status.busy": "2024-07-18T13:23:20.527606Z",
     "iopub.status.idle": "2024-07-18T13:23:20.532714Z",
     "shell.execute_reply": "2024-07-18T13:23:20.531528Z"
    },
    "papermill": {
     "duration": 0.029203,
     "end_time": "2024-07-18T13:23:20.535362",
     "exception": false,
     "start_time": "2024-07-18T13:23:20.506159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"<html><body><p> File </p><p> Author - Aman Khan</p><p> Click here to <a href='http://google.com'>download</a></p></body></html>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6bdf52b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:20.577472Z",
     "iopub.status.busy": "2024-07-18T13:23:20.577070Z",
     "iopub.status.idle": "2024-07-18T13:23:20.584212Z",
     "shell.execute_reply": "2024-07-18T13:23:20.583161Z"
    },
    "papermill": {
     "duration": 0.031145,
     "end_time": "2024-07-18T13:23:20.586823",
     "exception": false,
     "start_time": "2024-07-18T13:23:20.555678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' File  Author - Aman Khan Click here to download'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a52f4a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:20.631604Z",
     "iopub.status.busy": "2024-07-18T13:23:20.631217Z",
     "iopub.status.idle": "2024-07-18T13:23:20.893574Z",
     "shell.execute_reply": "2024-07-18T13:23:20.892462Z"
    },
    "papermill": {
     "duration": 0.286882,
     "end_time": "2024-07-18T13:23:20.896236",
     "exception": false,
     "start_time": "2024-07-18T13:23:20.609354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this show was an amazing, fresh & innovative idea in the 70's when it first aired. the first 7 or 8 years were brilliant, but things dropped off after that. by 1990, the show was not really funny anymore, and it's continued its decline further to the complete waste of time it is today.it's truly disgraceful how far this show has fallen. the writing is painfully bad, the performances are almost as bad - if not for the mildly entertaining respite of the guest-hosts, this show probably wouldn't still be on the air. i find it so hard to believe that the same creator that hand-selected the original cast also chose the band of hacks that followed. how can one recognize such brilliance and then see fit to replace it with such mediocrity? i felt i must give 2 stars out of respect for the original cast that made this show such a huge success. as it is now, the show is just awful. i can't believe it's still on the air.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tags)\n",
    "df['review'][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db85837b",
   "metadata": {
    "papermill": {
     "duration": 0.020461,
     "end_time": "2024-07-18T13:23:20.937841",
     "exception": false,
     "start_time": "2024-07-18T13:23:20.917380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Removing URLs\n",
    "\n",
    "In NLP, removing URLs from text is important for several reasons:\n",
    "\n",
    "1. **Noise Reduction**: URLs are often irrelevant to the text's main content and can introduce noise, affecting the quality of text analysis.\n",
    "\n",
    "2. **Normalization**: Like HTML tags, URLs can disrupt the uniform processing of text, complicating tokenization and other preprocessing steps.\n",
    "\n",
    "3. **Improved Model Performance**: Clean text without URLs helps NLP models focus on meaningful content, leading to better performance.\n",
    "\n",
    "4. **Consistency**: Removing URLs ensures a consistent text format across different sources, simplifying text processing and analysis.\n",
    "\n",
    "5. **Privacy and Security**: URLs can contain sensitive information or lead to security risks, so removing them helps in maintaining privacy and security.\n",
    "\n",
    "Overall, removing URLs is a standard preprocessing step to ensure cleaner, more consistent, and useful text for NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ab2c12a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:20.981334Z",
     "iopub.status.busy": "2024-07-18T13:23:20.980088Z",
     "iopub.status.idle": "2024-07-18T13:23:20.986603Z",
     "shell.execute_reply": "2024-07-18T13:23:20.985176Z"
    },
    "papermill": {
     "duration": 0.030948,
     "end_time": "2024-07-18T13:23:20.989141",
     "exception": false,
     "start_time": "2024-07-18T13:23:20.958193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd52ec",
   "metadata": {
    "papermill": {
     "duration": 0.020439,
     "end_time": "2024-07-18T13:23:21.030062",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.009623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This Python function `remove_url` is designed to remove URLs from a given text string.\n",
    "\n",
    "**Regular Expression Compilation**:\n",
    "   ```python\n",
    "   pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "   ```\n",
    "   This line compiles a regular expression (regex) pattern into a regex object for later use. The pattern `r'https?://\\S+|www\\.\\S+'` is used to match URLs:\n",
    "   - `https?://`: Matches `http://` or `https://`. The `s?` part makes the `s` optional, so it matches both `http` and `https`.\n",
    "   - `\\S+`: Matches one or more non-whitespace characters, effectively capturing the entire URL.\n",
    "   - `|`: Acts as an OR operator, meaning the pattern will match either the left side (`https?://\\S+`) or the right side (`www\\.\\S+`).\n",
    "   - `www\\.\\S+`: Matches URLs starting with `www.` followed by one or more non-whitespace characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3b813a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.073769Z",
     "iopub.status.busy": "2024-07-18T13:23:21.072682Z",
     "iopub.status.idle": "2024-07-18T13:23:21.078659Z",
     "shell.execute_reply": "2024-07-18T13:23:21.077448Z"
    },
    "papermill": {
     "duration": 0.030602,
     "end_time": "2024-07-18T13:23:21.081185",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.050583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text1 = 'Check out my Facecook https://www.facebook.com/'\n",
    "text2 = 'Check out my Instagram https://www.instagram.com/'\n",
    "text3 = 'Google search here www.google.com'\n",
    "text4 = 'For GitHub click https://github.com/ to search check www.google.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1aff93f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.123777Z",
     "iopub.status.busy": "2024-07-18T13:23:21.123399Z",
     "iopub.status.idle": "2024-07-18T13:23:21.131810Z",
     "shell.execute_reply": "2024-07-18T13:23:21.130670Z"
    },
    "papermill": {
     "duration": 0.033,
     "end_time": "2024-07-18T13:23:21.134525",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.101525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my Instagram '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a66f3",
   "metadata": {
    "papermill": {
     "duration": 0.02051,
     "end_time": "2024-07-18T13:23:21.175690",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.155180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Removing punctuation (!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~)\n",
    "\n",
    "In NLP, removing punctuation helps:\n",
    "\n",
    "1. **Simplify Text**: Reduces complexity for processing.\n",
    "2. **Normalize Data**: Ensures uniform text format.\n",
    "3. **Improve Tokenization**: Prevents punctuation from affecting word splits.\n",
    "4. **Enhance Model Performance**: Focuses on meaningful content for better results.\n",
    "5. **Size**: Punctuation makes the document large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20ada066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.219059Z",
     "iopub.status.busy": "2024-07-18T13:23:21.218638Z",
     "iopub.status.idle": "2024-07-18T13:23:21.226882Z",
     "shell.execute_reply": "2024-07-18T13:23:21.225659Z"
    },
    "papermill": {
     "duration": 0.033264,
     "end_time": "2024-07-18T13:23:21.229738",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.196474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string, time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2d67398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.273952Z",
     "iopub.status.busy": "2024-07-18T13:23:21.273132Z",
     "iopub.status.idle": "2024-07-18T13:23:21.280543Z",
     "shell.execute_reply": "2024-07-18T13:23:21.279133Z"
    },
    "papermill": {
     "duration": 0.03244,
     "end_time": "2024-07-18T13:23:21.283185",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.250745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude = string.punctuation\n",
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c75752a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.327207Z",
     "iopub.status.busy": "2024-07-18T13:23:21.326405Z",
     "iopub.status.idle": "2024-07-18T13:23:21.332179Z",
     "shell.execute_reply": "2024-07-18T13:23:21.331009Z"
    },
    "papermill": {
     "duration": 0.03048,
     "end_time": "2024-07-18T13:23:21.334563",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.304083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char, \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91d09f57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.441730Z",
     "iopub.status.busy": "2024-07-18T13:23:21.441370Z",
     "iopub.status.idle": "2024-07-18T13:23:21.446538Z",
     "shell.execute_reply": "2024-07-18T13:23:21.445369Z"
    },
    "papermill": {
     "duration": 0.030014,
     "end_time": "2024-07-18T13:23:21.449216",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.419202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Hello, world! This is a test: do you like it? Yes, I do... A lot; really! How about you? @username #hashtag $dollar %percent ^caret &amp *star (parentheses) -dash_underscore+plus=equals{curly}brackets[brackets]|\\backslash~tilde`backtick\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9db91b48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.493867Z",
     "iopub.status.busy": "2024-07-18T13:23:21.493149Z",
     "iopub.status.idle": "2024-07-18T13:23:21.500138Z",
     "shell.execute_reply": "2024-07-18T13:23:21.499032Z"
    },
    "papermill": {
     "duration": 0.032369,
     "end_time": "2024-07-18T13:23:21.502691",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.470322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world This is a test do you like it Yes I do A lot really How about you username hashtag dollar percent caret amp star parentheses dashunderscoreplusequalscurlybracketsbrackets\\x08ackslashtildebacktick'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punctuation(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "888b9068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.546669Z",
     "iopub.status.busy": "2024-07-18T13:23:21.546299Z",
     "iopub.status.idle": "2024-07-18T13:23:21.552497Z",
     "shell.execute_reply": "2024-07-18T13:23:21.551397Z"
    },
    "papermill": {
     "duration": 0.032077,
     "end_time": "2024-07-18T13:23:21.555928",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.523851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world This is a test do you like it Yes I do A lot really How about you username hashtag dollar percent caret amp star parentheses dashunderscoreplusequalscurlybracketsbrackets\backslashtildebacktick\n",
      "0.0001468658447265625\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(remove_punctuation(text))\n",
    "time1=time.time()-start\n",
    "print(time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c44aa457",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.601980Z",
     "iopub.status.busy": "2024-07-18T13:23:21.601148Z",
     "iopub.status.idle": "2024-07-18T13:23:21.607597Z",
     "shell.execute_reply": "2024-07-18T13:23:21.606454Z"
    },
    "papermill": {
     "duration": 0.031947,
     "end_time": "2024-07-18T13:23:21.610195",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.578248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_punctuation2(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b87b7fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.655166Z",
     "iopub.status.busy": "2024-07-18T13:23:21.654743Z",
     "iopub.status.idle": "2024-07-18T13:23:21.661175Z",
     "shell.execute_reply": "2024-07-18T13:23:21.659997Z"
    },
    "papermill": {
     "duration": 0.032666,
     "end_time": "2024-07-18T13:23:21.664243",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.631577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world This is a test do you like it Yes I do A lot really How about you username hashtag dollar percent caret amp star parentheses dashunderscoreplusequalscurlybracketsbrackets\backslashtildebacktick\n",
      "0.00016021728515625\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(remove_punctuation2(text))\n",
    "time2=time.time()-start\n",
    "print(time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba49dd",
   "metadata": {
    "papermill": {
     "duration": 0.021211,
     "end_time": "2024-07-18T13:23:21.706681",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.685470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Common chat abbreviations and slang\n",
    "\n",
    "Handling chat words in NLP is crucial for several reasons:\n",
    "\n",
    "1. **Improved Understanding**: Expanding chat abbreviations helps models better understand the content.\n",
    "2. **Contextual Accuracy**: Many chat words affect sentiment, tone, or intent (e.g., \"LOL\" vs. \"Laughing Out Loud\").\n",
    "3. **Data Normalization**: Ensures uniformity and consistency in text data, simplifying processing and analysis.\n",
    "4. **Enhanced Model Training**: Models trained on expanded forms of chat words perform more accurately.\n",
    "5. **Sentiment Analysis**: Properly handling chat words ensures more accurate sentiment detection (e.g., \"LMAO\" indicates strong amusement).\n",
    "6. **Readability**: Expanded chat words are clearer for both humans and NLP tasks like summarization or translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ebfa66e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.751374Z",
     "iopub.status.busy": "2024-07-18T13:23:21.750984Z",
     "iopub.status.idle": "2024-07-18T13:23:21.766774Z",
     "shell.execute_reply": "2024-07-18T13:23:21.765578Z"
    },
    "papermill": {
     "duration": 0.041173,
     "end_time": "2024-07-18T13:23:21.769241",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.728068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_word = {\n",
    "    'AFAIK': 'As Far As I Know',\n",
    "    'AFK': 'Away From Keyboard',\n",
    "    'ASAP': 'As Soon As Possible',\n",
    "    'ATK': 'At The Keyboard',\n",
    "    'ATM': 'At The Moment',\n",
    "    'A3': 'Anytime, Anywhere, Anyplace',\n",
    "    'BAK': 'Back At Keyboard',\n",
    "    'BBL': 'Be Back Later',\n",
    "    'BBS': 'Be Back Soon',\n",
    "    'BFN': 'Bye For Now',\n",
    "    'B4N': 'Bye For Now',\n",
    "    'BRB': 'Be Right Back',\n",
    "    'BRT': 'Be Right There',\n",
    "    'BTW': 'By The Way',\n",
    "    'B4': 'Before',\n",
    "    'CU': 'See You',\n",
    "    'CUL8R': 'See You Later',\n",
    "    'CYA': 'See You',\n",
    "    'FAQ': 'Frequently Asked Questions',\n",
    "    'FC': 'Fingers Crossed',\n",
    "    'FWIW': \"For What It's Worth\",\n",
    "    'FYI': 'For Your Information',\n",
    "    'GAL': 'Get A Life',\n",
    "    'GG': 'Good Game',\n",
    "    'GN': 'Good Night',\n",
    "    'GMTA': 'Great Minds Think Alike',\n",
    "    'GR8': 'Great!',\n",
    "    'G9': 'Genius',\n",
    "    'IC': 'I See',\n",
    "    'ICQ': 'I Seek you (also a chat program)',\n",
    "    'ILU': 'ILU: I Love You',\n",
    "    'IMHO': 'In My Honest/Humble Opinion',\n",
    "    'IMO': 'In My Opinion',\n",
    "    'IOW': 'In Other Words',\n",
    "    'IRL': 'In Real Life',\n",
    "    'KISS': 'Keep It Simple, Stupid',\n",
    "    'LDR': 'Long Distance Relationship',\n",
    "    'LMAO': 'Laugh My A.. Off',\n",
    "    'LOL': 'Laughing Out Loud',\n",
    "    'LTNS': 'Long Time No See',\n",
    "    'L8R': 'Later',\n",
    "    'MTE': 'My Thoughts Exactly',\n",
    "    'M8': 'Mate',\n",
    "    'NRN': 'No Reply Necessary',\n",
    "    'OIC': 'Oh I See',\n",
    "    'PITA': 'Pain In The A..',\n",
    "    'PRT': 'Party',\n",
    "    'PRW': 'Parents Are Watching',\n",
    "    'QPSA?': 'Que Pasa?',\n",
    "    'ROFL': 'Rolling On The Floor Laughing',\n",
    "    'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
    "    'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off',\n",
    "    'SK8': 'Skate',\n",
    "    'STATS': 'Your sex and age',\n",
    "    'ASL': 'Age, Sex, Location',\n",
    "    'THX': 'Thank You',\n",
    "    'TTFN': 'Ta-Ta For Now!',\n",
    "    'TTYL': 'Talk To You Later',\n",
    "    'U': 'You',\n",
    "    'U2': 'You Too',\n",
    "    'U4E': 'Yours For Ever',\n",
    "    'WB': 'Welcome Back',\n",
    "    'WTF': 'What The F...',\n",
    "    'WTG': 'Way To Go!',\n",
    "    'WUF': 'Where Are You From?',\n",
    "    'W8': 'Wait...',\n",
    "    '7K': 'Sick:-D Laugher',\n",
    "    'TFW': 'That feeling when',\n",
    "    'MFW': 'My face when',\n",
    "    'MRW': 'My reaction when',\n",
    "    'IFYP': 'I feel your pain',\n",
    "    'TNTL': 'Trying not to laugh',\n",
    "    'JK': 'Just kidding',\n",
    "    'IDC': \"I don't care\",\n",
    "    'ILY': 'I love you',\n",
    "    'IMU': 'I miss you',\n",
    "    'ADIH': 'Another day in hell',\n",
    "    'ZZZ': 'Sleeping, bored, tired',\n",
    "    'WYWH': 'Wish you were here',\n",
    "    'TIME': 'Tears in my eyes',\n",
    "    'BAE': 'Before anyone else',\n",
    "    'FIMH': 'Forever in my heart',\n",
    "    'BSAAW': 'Big smile and a wink',\n",
    "    'BWL': 'Bursting with laughter',\n",
    "    'BFF': 'Best friends forever',\n",
    "    'CSL': \"Can't stop laughing\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf850c16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.814199Z",
     "iopub.status.busy": "2024-07-18T13:23:21.813439Z",
     "iopub.status.idle": "2024-07-18T13:23:21.820191Z",
     "shell.execute_reply": "2024-07-18T13:23:21.819111Z"
    },
    "papermill": {
     "duration": 0.031784,
     "end_time": "2024-07-18T13:23:21.822598",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.790814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def short_conv(text):\n",
    "    new_text = []  # Initialize an empty list to hold the processed words\n",
    "    for w in text.split():  # Split the input text into words and iterate over them\n",
    "        if w.upper() in chat_word:  # Check if the uppercase version of the word is in the chat_word dictionary\n",
    "            new_text.append(chat_word[w.upper()])  # If it is, append the full form from the dictionary to new_text\n",
    "        else:\n",
    "            new_text.append(w)  # If it is not, append the original word to new_text\n",
    "    return \" \".join(new_text)  # Join the processed words into a single string and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c6fa6a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.870192Z",
     "iopub.status.busy": "2024-07-18T13:23:21.869260Z",
     "iopub.status.idle": "2024-07-18T13:23:21.876375Z",
     "shell.execute_reply": "2024-07-18T13:23:21.875273Z"
    },
    "papermill": {
     "duration": 0.034858,
     "end_time": "2024-07-18T13:23:21.878698",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.843840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Laughing Out Loud I will Be Right Back'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_conv(\"LOL I will BRB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae0a2bb",
   "metadata": {
    "papermill": {
     "duration": 0.021316,
     "end_time": "2024-07-18T13:23:21.922314",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.900998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Spelling correction\n",
    "\n",
    "Spelling correction in NLP is done to improve text quality and ensure accurate analysis. Correcting spelling errors helps in:\n",
    "\n",
    "1. **Enhanced Understanding**: Ensures that words are recognized correctly by NLP models.\n",
    "2. **Data Consistency**: Maintains uniformity in text data.\n",
    "3. **Improved Model Performance**: Reduces noise, leading to better model training and predictions.\n",
    "4. **Accurate Results**: Improves the accuracy of tasks like sentiment analysis, information retrieval, and machine translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faf7adf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:21.966717Z",
     "iopub.status.busy": "2024-07-18T13:23:21.966359Z",
     "iopub.status.idle": "2024-07-18T13:23:24.316191Z",
     "shell.execute_reply": "2024-07-18T13:23:24.315018Z"
    },
    "papermill": {
     "duration": 2.37513,
     "end_time": "2024-07-18T13:23:24.318747",
     "exception": false,
     "start_time": "2024-07-18T13:23:21.943617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The is an example of a sentence with several spelling errors.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "incorrect_text = \"Ths is an exmple of a sentnce with sevral speling erors.\"\n",
    "\n",
    "textblb = TextBlob(incorrect_text)\n",
    "textblb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b17d5a",
   "metadata": {
    "papermill": {
     "duration": 0.021409,
     "end_time": "2024-07-18T13:23:24.362210",
     "exception": false,
     "start_time": "2024-07-18T13:23:24.340801",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Removing StopWords\n",
    "\n",
    "Removing stop words in NLP text processing is like cleaning up unnecessary words like \"the\", \"is\", and \"and\" from sentences. These words appear frequently in language but don't add much meaning. By getting rid of them, we focus more on the important words that carry the actual message, making our analysis faster and more accurate. It's like decluttering a room so you can see and understand the important things better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0734f75a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:24.407256Z",
     "iopub.status.busy": "2024-07-18T13:23:24.406816Z",
     "iopub.status.idle": "2024-07-18T13:23:24.423913Z",
     "shell.execute_reply": "2024-07-18T13:23:24.422730Z"
    },
    "papermill": {
     "duration": 0.042631,
     "end_time": "2024-07-18T13:23:24.426482",
     "exception": false,
     "start_time": "2024-07-18T13:23:24.383851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acfeff11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:24.473359Z",
     "iopub.status.busy": "2024-07-18T13:23:24.472373Z",
     "iopub.status.idle": "2024-07-18T13:23:24.487402Z",
     "shell.execute_reply": "2024-07-18T13:23:24.486254Z"
    },
    "papermill": {
     "duration": 0.041285,
     "end_time": "2024-07-18T13:23:24.489895",
     "exception": false,
     "start_time": "2024-07-18T13:23:24.448610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick brown fox jumps   lazy dog. In  nutshell,       improve  writing skills  using  right words   right context.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "            \n",
    "    x = new_text[:]  # Create a copy of new_text\n",
    "    new_text.clear()  # Clear the original new_text list\n",
    "    return \" \".join(x)  # Join the copied list x into a single string separated by spaces and return it\n",
    "\n",
    "text = \"The quick brown fox jumps over the lazy dog. In a nutshell, it's all about how you can improve your writing skills by using the right words in the right context.\"\n",
    "remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bd87be0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:24.536641Z",
     "iopub.status.busy": "2024-07-18T13:23:24.536230Z",
     "iopub.status.idle": "2024-07-18T13:23:24.547516Z",
     "shell.execute_reply": "2024-07-18T13:23:24.546398Z"
    },
    "papermill": {
     "duration": 0.037544,
     "end_time": "2024-07-18T13:23:24.550000",
     "exception": false,
     "start_time": "2024-07-18T13:23:24.512456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad83709d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:24.597105Z",
     "iopub.status.busy": "2024-07-18T13:23:24.596699Z",
     "iopub.status.idle": "2024-07-18T13:23:24.601874Z",
     "shell.execute_reply": "2024-07-18T13:23:24.600707Z"
    },
    "papermill": {
     "duration": 0.032109,
     "end_time": "2024-07-18T13:23:24.604624",
     "exception": false,
     "start_time": "2024-07-18T13:23:24.572515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06708ed",
   "metadata": {
    "papermill": {
     "duration": 0.022648,
     "end_time": "2024-07-18T13:23:24.651706",
     "exception": false,
     "start_time": "2024-07-18T13:23:24.629058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Handling emojis\n",
    "\n",
    "Handling emojis in NLP text processing is important because emojis convey emotional and contextual information that traditional text alone may not fully capture. Here's why it matters:\n",
    "\n",
    "1. **Emotional Context**: Emojis provide emotional cues such as happiness , sadness , or surprise , which are crucial for sentiment analysis and understanding the tone of text.\n",
    "\n",
    "2. **Enhanced Meaning**: They enrich the meaning of text by adding nuances that words alone might not express effectively. For example, \"I'm excited!\" might convey more with a  emoji.\n",
    "\n",
    "3. **Communication Style**: Emojis reflect modern communication styles and can impact how messages are interpreted in social media, customer feedback, or online reviews.\n",
    "\n",
    "4. **Choice of Handling**: Depending on the application, emojis can be removed to focus purely on textual analysis, or they can be replaced with their textual description (emojis like  become \"smiling face with smiling eyes\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46a4c571",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:24.699060Z",
     "iopub.status.busy": "2024-07-18T13:23:24.698261Z",
     "iopub.status.idle": "2024-07-18T13:23:24.712086Z",
     "shell.execute_reply": "2024-07-18T13:23:24.710996Z"
    },
    "papermill": {
     "duration": 0.040107,
     "end_time": "2024-07-18T13:23:24.714487",
     "exception": false,
     "start_time": "2024-07-18T13:23:24.674380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm so excited for the party tonight!  Can't wait to see everyone there! \""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing Emojis\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern=re.compile(\"[\"\n",
    "                             u\"\\U0001F600-\\U0001F64F\" #emoticons\n",
    "                             u\"\\U0001F300-\\U0001F5FF\" #symbols, pictograph\n",
    "                              u\"\\U0001F680-\\U0001F6FF\" #transport and map symbol\n",
    "                              u\"\\U0001F1E0-\\U0001F1FF\" #flags(IOS)\n",
    "                              u\"\\U00002702-\\U000027B0\"\n",
    "                              u\"\\U00002FC2-\\U0001F251\"\n",
    "                             \"]+\",flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'',text)\n",
    "\n",
    "text=\"I'm so excited for the party tonight!  Can't wait to see everyone there! \"\n",
    "remove_emoji(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47ea29cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:24.762067Z",
     "iopub.status.busy": "2024-07-18T13:23:24.761632Z",
     "iopub.status.idle": "2024-07-18T13:23:24.835030Z",
     "shell.execute_reply": "2024-07-18T13:23:24.833680Z"
    },
    "papermill": {
     "duration": 0.100385,
     "end_time": "2024-07-18T13:23:24.837654",
     "exception": false,
     "start_time": "2024-07-18T13:23:24.737269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm so excited for the party tonight! :party_popper: Can't wait to see everyone there! :grinning_face_with_smiling_eyes:\n"
     ]
    }
   ],
   "source": [
    "#Replacing Emojis\n",
    "import emoji\n",
    "print(emoji.demojize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1860b7f",
   "metadata": {
    "papermill": {
     "duration": 0.022295,
     "end_time": "2024-07-18T13:23:24.882444",
     "exception": false,
     "start_time": "2024-07-18T13:23:24.860149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "#### What is Tokenization?\n",
    "\n",
    "Tokenization is the process of breaking down text into smaller pieces called tokens. These tokens can be words, phrases, or even individual characters, depending on the application. Think of it like cutting a paragraph into smaller, manageable parts.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "Imagine you have this sentence:\n",
    "\n",
    "```plaintext\n",
    "I love eating pizza!\n",
    "```\n",
    "\n",
    "When we tokenize it into words, it becomes:\n",
    "\n",
    "```plaintext\n",
    "[\"I\", \"love\", \"eating\", \"pizza\", \"!\"]\n",
    "```\n",
    "\n",
    "Each word and punctuation mark becomes a separate token.\n",
    "\n",
    "#### Why Do We Use Tokenization in NLP?\n",
    "\n",
    "1. **Easier Analysis**: Breaking text into tokens makes it easier to analyze. It's like reading a book one word at a time instead of trying to understand it all at once.\n",
    "   \n",
    "2. **Understanding Context**: It helps in understanding the context of each word in a sentence. For example, knowing that \"love\" is followed by \"eating\" gives a clear picture of the meaning.\n",
    "\n",
    "3. **Efficient Processing**: Computers can process and analyze tokens more efficiently than long strings of text. It speeds up tasks like searching for specific words or understanding the structure of sentences.\n",
    "\n",
    "4. **Building Blocks for NLP Tasks**: Tokenization is the first step for many NLP tasks like sentiment analysis, translation, and text summarization. It prepares the text for more complex processing.\n",
    "\n",
    "Tokenization helps break down text into smaller, understandable parts, making it easier for computers to analyze and work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014648d0",
   "metadata": {
    "papermill": {
     "duration": 0.022219,
     "end_time": "2024-07-18T13:23:24.927876",
     "exception": false,
     "start_time": "2024-07-18T13:23:24.905657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1. Split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b45cbba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:24.974679Z",
     "iopub.status.busy": "2024-07-18T13:23:24.974292Z",
     "iopub.status.idle": "2024-07-18T13:23:24.981586Z",
     "shell.execute_reply": "2024-07-18T13:23:24.980454Z"
    },
    "papermill": {
     "duration": 0.033622,
     "end_time": "2024-07-18T13:23:24.984012",
     "exception": false,
     "start_time": "2024-07-18T13:23:24.950390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'from', 'mumbai']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenization\n",
    "sent1 = 'I am from mumbai'\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3023a58b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:25.032510Z",
     "iopub.status.busy": "2024-07-18T13:23:25.031719Z",
     "iopub.status.idle": "2024-07-18T13:23:25.039369Z",
     "shell.execute_reply": "2024-07-18T13:23:25.038208Z"
    },
    "papermill": {
     "duration": 0.035027,
     "end_time": "2024-07-18T13:23:25.041762",
     "exception": false,
     "start_time": "2024-07-18T13:23:25.006735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to delhi',\n",
       " ' I will stay there for 3 days',\n",
       " \" Let's hope the trip to be great\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "sent2 = 'I am going to delhi. I will stay there for 3 days. Let\\'s hope the trip to be great'\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8ac5480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:25.089354Z",
     "iopub.status.busy": "2024-07-18T13:23:25.088974Z",
     "iopub.status.idle": "2024-07-18T13:23:25.096313Z",
     "shell.execute_reply": "2024-07-18T13:23:25.095007Z"
    },
    "papermill": {
     "duration": 0.034026,
     "end_time": "2024-07-18T13:23:25.098621",
     "exception": false,
     "start_time": "2024-07-18T13:23:25.064595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi!!!!']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problems with split function\n",
    "sent3 = 'I am going to delhi!!!!'\n",
    "sent3.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cad040dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:25.146661Z",
     "iopub.status.busy": "2024-07-18T13:23:25.146272Z",
     "iopub.status.idle": "2024-07-18T13:23:25.153539Z",
     "shell.execute_reply": "2024-07-18T13:23:25.152466Z"
    },
    "papermill": {
     "duration": 0.034201,
     "end_time": "2024-07-18T13:23:25.156069",
     "exception": false,
     "start_time": "2024-07-18T13:23:25.121868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where do think I should go? I have 3 day holiday']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problems with split function\n",
    "sent4 = 'Where do think I should go? I have 3 day holiday'\n",
    "sent4.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec6f11",
   "metadata": {
    "papermill": {
     "duration": 0.022862,
     "end_time": "2024-07-18T13:23:25.202410",
     "exception": false,
     "start_time": "2024-07-18T13:23:25.179548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2. Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5158602",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:25.250874Z",
     "iopub.status.busy": "2024-07-18T13:23:25.250466Z",
     "iopub.status.idle": "2024-07-18T13:23:25.258533Z",
     "shell.execute_reply": "2024-07-18T13:23:25.257324Z"
    },
    "papermill": {
     "duration": 0.035282,
     "end_time": "2024-07-18T13:23:25.261009",
     "exception": false,
     "start_time": "2024-07-18T13:23:25.225727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent3 = 'I am going to delhi!'\n",
    "tokens = re.findall(\"[\\w']+\", sent3)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51cb3831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:25.309776Z",
     "iopub.status.busy": "2024-07-18T13:23:25.309364Z",
     "iopub.status.idle": "2024-07-18T13:23:25.318041Z",
     "shell.execute_reply": "2024-07-18T13:23:25.316980Z"
    },
    "papermill": {
     "duration": 0.036088,
     "end_time": "2024-07-18T13:23:25.320631",
     "exception": false,
     "start_time": "2024-07-18T13:23:25.284543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry',\n",
       " \"\\nLorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "sentences = re.compile('[.!?] ').split(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4465745c",
   "metadata": {
    "papermill": {
     "duration": 0.023525,
     "end_time": "2024-07-18T13:23:25.368137",
     "exception": false,
     "start_time": "2024-07-18T13:23:25.344612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3. NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65e55aa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:25.417418Z",
     "iopub.status.busy": "2024-07-18T13:23:25.417037Z",
     "iopub.status.idle": "2024-07-18T13:23:25.423032Z",
     "shell.execute_reply": "2024-07-18T13:23:25.421731Z"
    },
    "papermill": {
     "duration": 0.033476,
     "end_time": "2024-07-18T13:23:25.425423",
     "exception": false,
     "start_time": "2024-07-18T13:23:25.391947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6d05416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:25.474996Z",
     "iopub.status.busy": "2024-07-18T13:23:25.474246Z",
     "iopub.status.idle": "2024-07-18T13:23:25.494311Z",
     "shell.execute_reply": "2024-07-18T13:23:25.493192Z"
    },
    "papermill": {
     "duration": 0.047658,
     "end_time": "2024-07-18T13:23:25.496799",
     "exception": false,
     "start_time": "2024-07-18T13:23:25.449141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'visit', 'delhi', '!']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'I am going to visit delhi!'\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0ea0088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:25.546860Z",
     "iopub.status.busy": "2024-07-18T13:23:25.546022Z",
     "iopub.status.idle": "2024-07-18T13:23:25.554927Z",
     "shell.execute_reply": "2024-07-18T13:23:25.553840Z"
    },
    "papermill": {
     "duration": 0.037113,
     "end_time": "2024-07-18T13:23:25.557880",
     "exception": false,
     "start_time": "2024-07-18T13:23:25.520767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry?',\n",
       " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0acf65b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:25.608020Z",
     "iopub.status.busy": "2024-07-18T13:23:25.607593Z",
     "iopub.status.idle": "2024-07-18T13:23:25.614864Z",
     "shell.execute_reply": "2024-07-18T13:23:25.613761Z"
    },
    "papermill": {
     "duration": 0.035733,
     "end_time": "2024-07-18T13:23:25.617812",
     "exception": false,
     "start_time": "2024-07-18T13:23:25.582079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']\n",
      "['We', \"'re\", 'here', 'to', 'help', '!', 'mail', 'us', 'at', 'nks', '@', 'gmail.com']\n",
      "['A', '5km', 'ride', 'cost', '$', '10.50']\n"
     ]
    }
   ],
   "source": [
    "sent5 = 'I have a Ph.D in A.I'\n",
    "sent6 = \"We're here to help! mail us at nks@gmail.com\" #Failed\n",
    "sent7 = 'A 5km ride cost $10.50' #Failed\n",
    "\n",
    "print(word_tokenize(sent5))\n",
    "print(word_tokenize(sent6))\n",
    "print(word_tokenize(sent7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7106045",
   "metadata": {
    "papermill": {
     "duration": 0.023559,
     "end_time": "2024-07-18T13:23:25.667305",
     "exception": false,
     "start_time": "2024-07-18T13:23:25.643746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4. Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c6f396a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:25.717947Z",
     "iopub.status.busy": "2024-07-18T13:23:25.717046Z",
     "iopub.status.idle": "2024-07-18T13:23:32.959959Z",
     "shell.execute_reply": "2024-07-18T13:23:32.958652Z"
    },
    "papermill": {
     "duration": 7.271293,
     "end_time": "2024-07-18T13:23:32.962835",
     "exception": false,
     "start_time": "2024-07-18T13:23:25.691542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc1 = nlp(sent5)\n",
    "doc2 = nlp(sent6)\n",
    "doc3 = nlp(sent7) #Failed\n",
    "doc4 = nlp(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63309649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:33.014134Z",
     "iopub.status.busy": "2024-07-18T13:23:33.013459Z",
     "iopub.status.idle": "2024-07-18T13:23:33.020088Z",
     "shell.execute_reply": "2024-07-18T13:23:33.018788Z"
    },
    "papermill": {
     "duration": 0.034789,
     "end_time": "2024-07-18T13:23:33.022829",
     "exception": false,
     "start_time": "2024-07-18T13:23:32.988040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5\n",
      "km\n",
      "ride\n",
      "cost\n",
      "$\n",
      "10.50\n"
     ]
    }
   ],
   "source": [
    "for token in doc3:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68fcd30",
   "metadata": {
    "papermill": {
     "duration": 0.023956,
     "end_time": "2024-07-18T13:23:33.071512",
     "exception": false,
     "start_time": "2024-07-18T13:23:33.047556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Stemming\n",
    "\n",
    "#### What is Stemming?\n",
    "\n",
    "Stemming is the process of reducing words to their base or root form. It's like finding the \"stem\" of a word, which can help us understand different variations of the same word.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "Imagine you have these words:\n",
    "\n",
    "```plaintext\n",
    "running, runner, runs, ran\n",
    "```\n",
    "\n",
    "When we apply stemming, they all get reduced to the root form:\n",
    "\n",
    "```plaintext\n",
    "run\n",
    "```\n",
    "\n",
    "So, \"running\", \"runner\", \"runs\", and \"ran\" all become \"run\".\n",
    "\n",
    "#### Why Do We Use Stemming in NLP?\n",
    "\n",
    "1. **Simplifies Text**: Stemming simplifies words to their root form, which makes it easier to analyze text. For instance, \"running\" and \"ran\" are different forms of the same concept, and stemming helps treat them as one.\n",
    "\n",
    "2. **Reduces Complexity**: By converting different forms of a word to a common base, stemming reduces the number of unique words in a text. This makes the analysis more manageable and less complex.\n",
    "\n",
    "3. **Improves Search Results**: In tasks like search engines or information retrieval, stemming helps find relevant documents by matching different word forms. For example, searching for \"run\" will also return results for \"running\" and \"ran\".\n",
    "\n",
    "4. **Consistent Analysis**: It ensures that variations of a word are consistently analyzed together, improving the accuracy of tasks like text classification, sentiment analysis, and topic modeling.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "If you are building a program to understand customer reviews, you might have sentences like:\n",
    "\n",
    "```plaintext\n",
    "I enjoyed running in the park.\n",
    "She runs every morning.\n",
    "He is a fast runner.\n",
    "Yesterday, I ran for an hour.\n",
    "```\n",
    "\n",
    "Stemming will reduce \"running\", \"runs\", \"runner\", and \"ran\" to the common root \"run\". This way, your program understands that all these sentences are about the activity of running.\n",
    "\n",
    "Stemming helps simplify and standardize words in text, making it easier for computers to analyze and understand different forms of words as part of the same concept.\n",
    "\n",
    "### What is a Stemmer?\n",
    "\n",
    "A stemmer is a tool in NLP that reduces words to their root form or base form. This helps in simplifying and standardizing words for easier analysis.\n",
    "\n",
    "### PorterStemmer:\n",
    "\n",
    "- **Developed by**: Martin Porter in 1980.\n",
    "- **Characteristics**: \n",
    "  - It's one of the oldest and most widely used stemming algorithms.\n",
    "  - It uses a set of rules to iteratively strip suffixes from words.\n",
    "  - Known for its simplicity and efficiency.\n",
    "- **Example**:\n",
    "  ```plaintext\n",
    "  \"running\", \"runner\", \"runs\" -> \"run\"\n",
    "  ```\n",
    "\n",
    "### Snowball Stemmer:\n",
    "\n",
    "- **Developed by**: Martin Porter as well, it's an improvement over the original Porter Stemmer.\n",
    "- **Characteristics**:\n",
    "  - Also known as the Porter2 Stemmer.\n",
    "  - More aggressive and efficient compared to the original Porter Stemmer.\n",
    "  - Supports multiple languages, unlike the original Porter Stemmer which is English-only.\n",
    "- **Example**:\n",
    "  ```plaintext\n",
    "  \"running\", \"runner\", \"runs\" -> \"run\"\n",
    "  ```\n",
    "\n",
    "Both stemmers aim to reduce words to their root form, the Snowball Stemmer is a more advanced and versatile version of the original Porter Stemmer, supporting additional languages and more sophisticated stemming rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa56ff9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:33.123081Z",
     "iopub.status.busy": "2024-07-18T13:23:33.122173Z",
     "iopub.status.idle": "2024-07-18T13:23:33.128401Z",
     "shell.execute_reply": "2024-07-18T13:23:33.127214Z"
    },
    "papermill": {
     "duration": 0.034833,
     "end_time": "2024-07-18T13:23:33.130887",
     "exception": false,
     "start_time": "2024-07-18T13:23:33.096054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d22c0e80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:33.181644Z",
     "iopub.status.busy": "2024-07-18T13:23:33.180617Z",
     "iopub.status.idle": "2024-07-18T13:23:33.188487Z",
     "shell.execute_reply": "2024-07-18T13:23:33.187300Z"
    },
    "papermill": {
     "duration": 0.03609,
     "end_time": "2024-07-18T13:23:33.191311",
     "exception": false,
     "start_time": "2024-07-18T13:23:33.155221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run run run run'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"running run runs runned\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d1a16ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:33.242182Z",
     "iopub.status.busy": "2024-07-18T13:23:33.241326Z",
     "iopub.status.idle": "2024-07-18T13:23:33.247631Z",
     "shell.execute_reply": "2024-07-18T13:23:33.246448Z"
    },
    "papermill": {
     "duration": 0.035158,
     "end_time": "2024-07-18T13:23:33.250920",
     "exception": false,
     "start_time": "2024-07-18T13:23:33.215762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie\n"
     ]
    }
   ],
   "source": [
    "text = 'probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60e09d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:33.302141Z",
     "iopub.status.busy": "2024-07-18T13:23:33.301135Z",
     "iopub.status.idle": "2024-07-18T13:23:33.312223Z",
     "shell.execute_reply": "2024-07-18T13:23:33.311123Z"
    },
    "papermill": {
     "duration": 0.039253,
     "end_time": "2024-07-18T13:23:33.314636",
     "exception": false,
     "start_time": "2024-07-18T13:23:33.275383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probabl my alltim favorit movi a stori of selfless sacrific and dedic to a nobl caus but it not preachi or bore it just never get old despit my have seen it some 15 or more time in the last 25 year paul luka perform bring tear to my eye and bett davi in one of her veri few truli sympathet role is a delight the kid are as grandma say more like dressedup midget than children but that onli make them more fun to watch and the mother slow awaken to what happen in the world and under her own roof is believ and startl if i had a dozen thumb theyd all be up for thi movi'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af726d66",
   "metadata": {
    "papermill": {
     "duration": 0.02414,
     "end_time": "2024-07-18T13:23:33.363514",
     "exception": false,
     "start_time": "2024-07-18T13:23:33.339374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Disadvantages of Stemming\n",
    "\n",
    "1. **Over-Simplification**: Stemming can sometimes be too aggressive, reducing words to forms that are not real words (e.g., \"better\" becoming \"bett\").\n",
    "\n",
    "2. **Loss of Meaning**: Important nuances and meanings might be lost when words are reduced to their base form (e.g., \"running\" and \"runner\" both becoming \"run\").\n",
    "\n",
    "3. **Inconsistency**: Different stemming algorithms might produce different results for the same word, leading to inconsistency in text analysis.\n",
    "\n",
    "4. **Language Limitations**: Some stemmers are designed for specific languages and might not work well with others.\n",
    "\n",
    "Stemming helps in simplifying text, it can sometimes go too far, losing important details and creating inconsistencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da819fed",
   "metadata": {
    "papermill": {
     "duration": 0.024557,
     "end_time": "2024-07-18T13:23:33.412492",
     "exception": false,
     "start_time": "2024-07-18T13:23:33.387935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Lemmatization\n",
    "\n",
    "#### What is Lemmatization?\n",
    "\n",
    "Lemmatization is the process of reducing words to their base or dictionary form, known as the lemma. Unlike stemming, which cuts off word endings, lemmatization considers the context and converts words to their actual root form as found in the dictionary.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "Imagine you have these words:\n",
    "\n",
    "```plaintext\n",
    "running, ran, runs\n",
    "```\n",
    "\n",
    "Lemmatization converts them all to:\n",
    "\n",
    "```plaintext\n",
    "run\n",
    "```\n",
    "\n",
    "#### Why Do We Use Lemmatization in NLP?\n",
    "\n",
    "1. **Accurate Base Forms**: It provides accurate base forms of words, maintaining the meaning. For example, \"better\" becomes \"good,\" which is its true lemma.\n",
    "   \n",
    "2. **Improves Understanding**: Helps in understanding the text better by converting words to their proper form, making it easier for NLP models to analyze.\n",
    "\n",
    "3. **Consistent Analysis**: Ensures consistency in text analysis by using standardized forms of words.\n",
    "\n",
    "#### What is a Lemma?\n",
    "\n",
    "A lemma is the base or dictionary form of a word. For instance, the lemma of \"running\" and \"ran\" is \"run.\"\n",
    "\n",
    "Lemmatization is like looking up the correct word form in the dictionary. It helps computers understand and process text more accurately by converting words to their true base form. This way, words like \"running\" and \"ran\" are understood to be the same action, \"run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40a4333a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T13:23:33.464675Z",
     "iopub.status.busy": "2024-07-18T13:23:33.464289Z",
     "iopub.status.idle": "2024-07-18T13:23:34.732218Z",
     "shell.execute_reply": "2024-07-18T13:23:34.730864Z"
    },
    "papermill": {
     "duration": 1.296679,
     "end_time": "2024-07-18T13:23:34.734894",
     "exception": false,
     "start_time": "2024-07-18T13:23:33.438215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n",
      "Word - Lemma\n",
      "Apple - Apple\n",
      "is - be\n",
      "looking - look\n",
      "at - at\n",
      "buying - buy\n",
      "U.K. - U.K.\n",
      "startup - startup\n",
      "for - for\n",
      "$ - $\n",
      "1 - 1\n",
      "billion - billion\n",
      ". - .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the small English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Process a text\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion.\")\n",
    "\n",
    "# Print named entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "    \n",
    "print(\"Word - Lemma\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} - {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4ad777",
   "metadata": {
    "papermill": {
     "duration": 0.024528,
     "end_time": "2024-07-18T13:23:34.784634",
     "exception": false,
     "start_time": "2024-07-18T13:23:34.760106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## When to Use Stemming or Lemmatization?\n",
    "\n",
    "#### **Stemming:**\n",
    "\n",
    "- **Quick and Simple**: Use stemming when you need fast results and don't care about perfect accuracy.\n",
    "- **Large Datasets**: It's good for handling large amounts of text quickly.\n",
    "- **Internal Use**: Best for when the text won't be shown to others, like internal processing or quick keyword matching.\n",
    "\n",
    "#### **Lemmatization:**\n",
    "\n",
    "- **Accurate and Contextual**: Use lemmatization for more accurate word forms and better understanding.\n",
    "- **Complex Tasks**: Ideal for tasks like sentiment analysis or translation where meaning matters.\n",
    "- **Readable Output**: Choose lemmatization when the text will be shown to others, ensuring it looks correct and makes sense.\n",
    "\n",
    "Use stemming for speed and simplicity when the text is for internal use, and go for lemmatization when accuracy and readability are important."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 134715,
     "sourceId": 320111,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.104936,
   "end_time": "2024-07-18T13:23:36.334250",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-18T13:23:14.229314",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
